{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srujany/Statistics/blob/main/jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What are the three measures of central tendency?"
      ],
      "metadata": {
        "id": "L7WqnsRZ_QLd"
      },
      "id": "L7WqnsRZ_QLd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The three measures of central tendency are:\n",
        "\n",
        "1. **Mean**: The average of a set of numbers, calculated by adding all the values together and then dividing by the number of values.\n",
        "\n",
        "2. **Median**: The middle value in a set of numbers when they are arranged in order. If there’s an even number of values, the median is the average of the two middle values.\n",
        "\n",
        "3. **Mode**: The value that occurs most frequently in a data set. If no value repeats, there is no mode.\n",
        "\n",
        "Each of these measures provides different insights into the \"center\" or typical value of a data set."
      ],
      "metadata": {
        "id": "Doklhfcd_gcq"
      },
      "id": "Doklhfcd_gcq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the difference between the mean, median, and mode? How are they used to measure the\n",
        "central tendency of a dataset"
      ],
      "metadata": {
        "id": "3cKeU8l__qCU"
      },
      "id": "3cKeU8l__qCU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **mean**, **median**, and **mode** are all measures of central tendency, but they each describe the \"center\" of a dataset in different ways. Here's how they differ:\n",
        "\n",
        "1. **Mean**:\n",
        "   - **Definition**: The mean is the average of all the values in a dataset.\n",
        "   - **Calculation**: Add all the numbers together and divide by the total number of values.\n",
        "   - **Use**: The mean is sensitive to extreme values (outliers), so it might not represent the center well if the dataset has large outliers.\n",
        "   - **Example**: For the dataset 3, 5, 7, 10, the mean is (3 + 5 + 7 + 10) / 4 = 6.25.\n",
        "\n",
        "2. **Median**:\n",
        "   - **Definition**: The median is the middle value in an ordered dataset. If there’s an even number of values, the median is the average of the two middle values.\n",
        "   - **Calculation**: Arrange the data in ascending or descending order, then pick the middle value. If there is an even number of values, calculate the average of the two middle values.\n",
        "   - **Use**: The median is not affected by outliers or skewed data, so it is a better measure of central tendency when dealing with data that has extreme values.\n",
        "   - **Example**: For the dataset 3, 5, 7, 10, the median is (5 + 7) / 2 = 6.\n",
        "\n",
        "3. **Mode**:\n",
        "   - **Definition**: The mode is the value that occurs most frequently in a dataset.\n",
        "   - **Calculation**: Identify the value that appears most often.\n",
        "   - **Use**: The mode is useful for categorical or nominal data and helps identify the most common value. It can have multiple modes (bimodal, multimodal) or no mode if all values are unique.\n",
        "   - **Example**: For the dataset 3, 5, 7, 5, the mode is 5 because it appears twice.\n",
        "\n",
        "### How They Measure Central Tendency:\n",
        "- **Mean**: Provides the overall \"average\" and works well for symmetric datasets with no outliers.\n",
        "- **Median**: Represents the \"middle\" value and is ideal when the data is skewed or contains outliers, as it’s less influenced by extreme values.\n",
        "- **Mode**: Identifies the most frequent value and is especially useful for categorical data or when identifying the most common value is important.\n",
        "\n",
        "In summary, each measure gives a different perspective on the central point of a dataset. The **mean** gives an overall average, the **median** shows the middle value, and the **mode** highlights the most frequent value."
      ],
      "metadata": {
        "id": "R6SoE7Ve_9rF"
      },
      "id": "R6SoE7Ve_9rF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Measure the three measures of central tendency for the given height data:\n",
        "\n",
        " [178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]"
      ],
      "metadata": {
        "id": "G5s95WOVAD3X"
      },
      "id": "G5s95WOVAD3X"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = [178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]\n",
        "\n",
        "mean = np.mean(data)\n",
        "median = np.median(data)\n",
        "mode = np.argmax(np.bincount(data))\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Median: {median}\")\n",
        "print(f\"Mode: {mode}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctSqnFHjALKw",
        "outputId": "c12d1d0f-c857-4cc6-83aa-bfb89a7d78b0"
      },
      "id": "ctSqnFHjALKw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 177.01875\n",
            "Median: 177.0\n",
            "Mode: 178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. How are measures of dispersion such as range, variance, and standard deviation used to describe\n",
        "the spread of a dataset? Provide an example."
      ],
      "metadata": {
        "id": "DMjEcp90AjDG"
      },
      "id": "DMjEcp90AjDG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measures of dispersion, such as **range**, **variance**, and **standard deviation**, are used to describe the spread or variability of a dataset. These measures help us understand how much the data points differ from the central tendency (mean, median, or mode) and from each other.\n",
        "\n",
        "Here’s how each measure is used:\n",
        "\n",
        "### 1. **Range**:\n",
        "   - **Definition**: The range is the difference between the largest and smallest values in the dataset.\n",
        "   - **Calculation**: Subtract the minimum value from the maximum value.\n",
        "   - **Use**: The range provides a simple measure of the spread, but it is sensitive to outliers. If there are extreme values in the dataset, the range will be large.\n",
        "   - **Example**:\n",
        "     - Dataset: 3, 5, 7, 10\n",
        "     - Range = 10 - 3 = 7\n",
        "     - The range indicates that the data spread across a distance of 7 units.\n",
        "\n",
        "### 2. **Variance**:\n",
        "   - **Definition**: Variance measures how far each data point is from the mean and, on average, how much the data points differ from the mean.\n",
        "   - **Calculation**: Find the mean of the dataset, subtract the mean from each data point, square the result, and then average those squared differences.\n",
        "   - **Formula**:  \n",
        "     \\[\n",
        "     \\text{Variance} = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\mu)^2\n",
        "     \\]\n",
        "     where \\( x_i \\) is each data point, \\( \\mu \\) is the mean, and \\( N \\) is the total number of data points.\n",
        "   - **Use**: Variance gives a precise measure of dispersion, but because it squares the differences, it is expressed in squared units, which makes it hard to interpret directly.\n",
        "   - **Example**:\n",
        "     - Dataset: 3, 5, 7, 10\n",
        "     - Mean = (3 + 5 + 7 + 10) / 4 = 6.25\n",
        "     - Variance calculation involves subtracting the mean from each data point, squaring the differences, and averaging them.\n",
        "\n",
        "### 3. **Standard Deviation**:\n",
        "   - **Definition**: The standard deviation is the square root of the variance. It measures the average amount of variation or dispersion in a dataset.\n",
        "   - **Calculation**: It is simply the square root of the variance, so it brings the unit of measurement back to the same scale as the original data.\n",
        "   - **Use**: The standard deviation is widely used because it is expressed in the same unit as the data, making it easier to understand compared to variance.\n",
        "   - **Example**:\n",
        "     - If the variance of the dataset 3, 5, 7, 10 is calculated to be 5.1875, the standard deviation would be the square root of that, approximately **2.27**.\n",
        "     - This means that, on average, the data points deviate from the mean by about 2.27 units.\n",
        "\n",
        "### Example: Dataset = 3, 5, 7, 10\n",
        "\n",
        "1. **Range**:  \n",
        "   - Max = 10, Min = 3  \n",
        "   - Range = 10 - 3 = 7\n",
        "  \n",
        "2. **Variance**:  \n",
        "   - Mean = 6.25  \n",
        "   - Differences from the mean: (3 - 6.25), (5 - 6.25), (7 - 6.25), (10 - 6.25) = -3.25, -1.25, 0.75, 3.75  \n",
        "   - Squared differences: 10.5625, 1.5625, 0.5625, 14.0625  \n",
        "   - Average squared difference = (10.5625 + 1.5625 + 0.5625 + 14.0625) / 4 = 5.1875  \n",
        "   - Variance = 5.1875\n",
        "\n",
        "3. **Standard Deviation**:  \n",
        "   - Standard Deviation = √5.1875 ≈ **2.27**\n",
        "\n",
        "### Summary of How These Measures Describe Spread:\n",
        "- **Range**: Tells us the overall spread between the smallest and largest values but can be influenced by outliers.\n",
        "- **Variance**: Quantifies the spread of the data points in terms of squared deviations from the mean, giving us a more nuanced view of variability.\n",
        "- **Standard Deviation**: Provides a more interpretable measure of spread, expressed in the same units as the data, and shows how much individual data points typically deviate from the mean.\n",
        "\n",
        "These measures help assess the **consistency** or **variability** of data, which is crucial in many real-world applications, such as predicting outcomes, risk management, or understanding the stability of a process or system."
      ],
      "metadata": {
        "id": "XNKLT6_3A-9z"
      },
      "id": "XNKLT6_3A-9z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What is a Venn diagram?"
      ],
      "metadata": {
        "id": "2-YRzEIxB8KI"
      },
      "id": "2-YRzEIxB8KI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **Venn diagram** is a visual representation used to show the relationships between different sets or groups. It uses circles (or other shapes) to represent each set, and the overlapping regions of the circles show the relationships or common elements between those sets.\n",
        "\n",
        "### Key Features of a Venn Diagram:\n",
        "- **Circles or Shapes**: Each circle represents a set of items or elements.\n",
        "- **Overlapping Areas**: The overlapping part of two or more circles shows the items that are common to the sets.\n",
        "- **Non-overlapping Areas**: The parts of the circles that do not overlap show the items that belong exclusively to that set.\n",
        "- **Universal Set**: Sometimes, a rectangle or larger box surrounds the circles, representing the \"universe\" or the total collection of all items being considered.\n",
        "\n",
        "### Example:\n",
        "Imagine two sets:\n",
        "- Set A: {1, 2, 3, 4}\n",
        "- Set B: {3, 4, 5, 6}\n",
        "\n",
        "A Venn diagram would show two circles, one representing Set A and the other representing Set B. The numbers 3 and 4 would appear in the overlapping area, as they are common to both sets. The numbers 1 and 2 would be only in the circle for Set A, and 5 and 6 would be only in the circle for Set B.\n",
        "\n",
        "### Uses:\n",
        "- **Set Theory**: To show relationships like intersections (common elements), unions (all elements from both sets), and differences (elements only in one set).\n",
        "- **Logic**: To visualize logical relationships between sets, like \"AND\" or \"OR\" conditions.\n",
        "- **Problem Solving**: Used in math, statistics, and probability to analyze relationships between groups.\n",
        "  \n",
        "Venn diagrams are a simple but powerful tool for understanding and analyzing the relationships between different categories or groups of data."
      ],
      "metadata": {
        "id": "KqUU_Rc2CDXw"
      },
      "id": "KqUU_Rc2CDXw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. For the two given sets A = (2,3,4,5,6,7) & B = (0,2,6,8,10). Find:\n",
        "\n",
        "(i) \tA B\n",
        "\n",
        "(ii)\tA ⋃ B"
      ],
      "metadata": {
        "id": "vJxiQXGTCR2o"
      },
      "id": "vJxiQXGTCR2o"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "A = {2,3,4,5,6,7}\n",
        "B = {0,2,6,8,10}\n",
        "a = A.intersection(B)\n",
        "b = A.union(B)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYh_-PfxCa2B",
        "outputId": "0b690f7c-8133-4f97-ec33-55f6101ce5a0"
      },
      "id": "AYh_-PfxCa2B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2, 6}\n",
            "{0, 2, 3, 4, 5, 6, 7, 8, 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What do you understand about skewness in data?"
      ],
      "metadata": {
        "id": "ernNvWoDDnor"
      },
      "id": "ernNvWoDDnor"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Skewness** in data refers to the degree of asymmetry or departure from symmetry in the distribution of a dataset. In other words, it describes whether the data is stretched or pulled to one side (left or right) relative to its mean, or if it is relatively symmetrical.\n",
        "\n",
        "### Types of Skewness:\n",
        "\n",
        "1. **Positive Skew (Right Skew)**:\n",
        "   - **Definition**: In a positively skewed distribution, the right tail (larger values) is longer than the left tail (smaller values). This means that the majority of data points are concentrated on the left side of the mean.\n",
        "   - **Characteristics**:\n",
        "     - Mean > Median > Mode\n",
        "     - There are a few large values (outliers) pulling the distribution to the right.\n",
        "   - **Example**: Income distribution (most people earn moderate incomes, but a few people earn extremely high incomes, causing a right skew).\n",
        "\n",
        "2. **Negative Skew (Left Skew)**:\n",
        "   - **Definition**: In a negatively skewed distribution, the left tail (smaller values) is longer than the right tail (larger values). This means that most of the data points are concentrated on the right side of the mean.\n",
        "   - **Characteristics**:\n",
        "     - Mean < Median < Mode\n",
        "     - There are a few very small values (outliers) pulling the distribution to the left.\n",
        "   - **Example**: Age at retirement (most people retire later in life, but a few retire very early, causing a left skew).\n",
        "\n",
        "3. **No Skew (Symmetrical Distribution)**:\n",
        "   - **Definition**: When the data is perfectly symmetrical, the tails on both sides of the mean are of equal length. This is often seen in a normal distribution (bell curve).\n",
        "   - **Characteristics**:\n",
        "     - Mean = Median = Mode\n",
        "     - There is no skewness, and the data is evenly spread around the center.\n",
        "   - **Example**: Heights of adult humans (with no extreme outliers, the distribution is roughly symmetrical).\n",
        "\n",
        "### How to Measure Skewness:\n",
        "Skewness can be quantified numerically using formulas or statistical software. A common formula for skewness is:\n",
        "\n",
        "\\[\n",
        "\\text{Skewness} = \\frac{n}{(n-1)(n-2)} \\sum \\left( \\frac{x_i - \\bar{x}}{s} \\right)^3\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\(x_i\\) are the data points\n",
        "- \\(\\bar{x}\\) is the mean\n",
        "- \\(s\\) is the standard deviation\n",
        "- \\(n\\) is the number of data points\n",
        "\n",
        "- **Positive skew**: If skewness is greater than 0, the distribution is positively skewed.\n",
        "- **Negative skew**: If skewness is less than 0, the distribution is negatively skewed.\n",
        "- **Zero skew**: If skewness is close to 0, the distribution is symmetrical.\n",
        "\n",
        "### Why is Skewness Important?\n",
        "- **Data Interpretation**: Skewness provides insight into how data is distributed. Understanding the direction and extent of skewness can help in selecting appropriate statistical methods and models.\n",
        "- **Choosing the Right Analysis**: For skewed data, measures like the **median** and **mode** may be more representative of the central tendency than the mean, which can be influenced by extreme values.\n",
        "- **Assumptions for Models**: Many statistical models (like linear regression) assume that data is normally distributed. If data is highly skewed, transformations or non-parametric methods may be required.\n",
        "\n",
        "### Example of Skewness:\n",
        "Imagine a dataset of test scores: {45, 50, 51, 60, 65, 90, 98, 100, 150, 200}\n",
        "\n",
        "- The distribution is **positively skewed** (right skew) because there are a few very high test scores (150, 200) pulling the tail to the right. Most scores are closer to the lower end of the range.\n",
        "\n",
        "In summary, **skewness** tells us how data is distributed around its mean and whether the distribution is symmetrical or stretched toward one side. Recognizing skewness is important in choosing the right statistical approach for analyzing data."
      ],
      "metadata": {
        "id": "y_yHsydWD3Fy"
      },
      "id": "y_yHsydWD3Fy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. If a data is right skewed then what will be the position of median with respect to mean?"
      ],
      "metadata": {
        "id": "gnT488rpRfM1"
      },
      "id": "gnT488rpRfM1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the data is **right-skewed** (positively skewed), the **mean** will be greater than the **median**.\n",
        "\n",
        "### Explanation:\n",
        "- In a **right-skewed** distribution, the right tail (larger values) is longer, and there are a few **large outliers** that pull the mean to the right.\n",
        "- The **mean** is more sensitive to these extreme values, causing it to be higher than the **median**.\n",
        "- The **median**, which represents the middle value of the dataset, is less affected by outliers and thus remains closer to the center of the data.\n",
        "\n",
        "### General Relationship in a Right-Skewed Distribution:\n",
        "- **Mean > Median > Mode**\n",
        "\n",
        "So, in a right-skewed dataset, the **mean** will be positioned to the right of the **median**."
      ],
      "metadata": {
        "id": "KzvVWwReRlnq"
      },
      "id": "KzvVWwReRlnq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. Explain the difference between covariance and correlation. How are these measures used in\n",
        "statistical analysis?"
      ],
      "metadata": {
        "id": "TTLGMUJgR4Pn"
      },
      "id": "TTLGMUJgR4Pn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Covariance** and **correlation** are both statistical measures that describe the relationship between two variables, but they differ in their scale, interpretation, and the type of information they provide. Here's an explanation of the key differences between them:\n",
        "\n",
        "### 1. **Covariance**:\n",
        "   - **Definition**: Covariance measures the **direction** of the linear relationship between two variables. It indicates whether two variables tend to increase or decrease together (i.e., whether they have a positive or negative relationship).\n",
        "   - **Formula**:\n",
        "     \\[\n",
        "     \\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})\n",
        "     \\]\n",
        "     Where:\n",
        "     - \\(X_i\\) and \\(Y_i\\) are the individual data points of variables \\(X\\) and \\(Y\\),\n",
        "     - \\(\\bar{X}\\) and \\(\\bar{Y}\\) are the means of \\(X\\) and \\(Y\\),\n",
        "     - \\(n\\) is the number of data points.\n",
        "\n",
        "   - **Range**: Covariance can take any value from negative infinity to positive infinity. The scale of covariance depends on the units of the variables, which can make it difficult to compare across different datasets.\n",
        "     - **Positive Covariance**: If \\(X\\) and \\(Y\\) increase together (positive relationship).\n",
        "     - **Negative Covariance**: If one variable increases while the other decreases (negative relationship).\n",
        "     - **Zero Covariance**: No linear relationship between the variables.\n",
        "\n",
        "   - **Limitations**: The magnitude of covariance is not standardized, so it's difficult to compare the strength of relationships between datasets with different units or scales.\n",
        "\n",
        "### 2. **Correlation**:\n",
        "   - **Definition**: Correlation measures both the **strength** and **direction** of the linear relationship between two variables. It standardizes the covariance, making it easier to interpret and compare relationships across different datasets.\n",
        "   - **Formula**:\n",
        "     \\[\n",
        "     \\text{Correlation (r)} = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n",
        "     \\]\n",
        "     Where:\n",
        "     - \\(\\text{Cov}(X, Y)\\) is the covariance between \\(X\\) and \\(Y\\),\n",
        "     - \\(\\sigma_X\\) and \\(\\sigma_Y\\) are the standard deviations of \\(X\\) and \\(Y\\), respectively.\n",
        "\n",
        "   - **Range**: Correlation values range from **-1 to 1**:\n",
        "     - **1** indicates a perfect positive linear relationship.\n",
        "     - **-1** indicates a perfect negative linear relationship.\n",
        "     - **0** indicates no linear relationship.\n",
        "   \n",
        "   - **Interpretation**:\n",
        "     - **Positive correlation**: When \\(r\\) is between 0 and 1, the variables have a positive relationship.\n",
        "     - **Negative correlation**: When \\(r\\) is between -1 and 0, the variables have a negative relationship.\n",
        "     - **Zero correlation**: \\(r = 0\\) indicates no linear relationship.\n",
        "\n",
        "   - **Advantages**: Correlation is unit-free, meaning it's not affected by the units of measurement of the variables. This allows for easier comparison across datasets.\n",
        "\n",
        "### Key Differences:\n",
        "\n",
        "| **Aspect**         | **Covariance**                             | **Correlation**                            |\n",
        "|--------------------|--------------------------------------------|--------------------------------------------|\n",
        "| **Definition**      | Measures the direction of the linear relationship between two variables. | Measures both the strength and direction of the linear relationship. |\n",
        "| **Range**           | Unrestricted; can be any value from \\(-\\infty\\) to \\(+\\infty\\). | Ranges from -1 to +1. |\n",
        "| **Interpretation**  | Tells whether variables move in the same direction (positive) or opposite direction (negative). | Tells the strength and direction of the relationship, with values between -1 and 1. |\n",
        "| **Units**           | Dependent on the units of the variables, which can make it difficult to compare across datasets. | Unit-free; easy to compare across datasets. |\n",
        "| **Use**             | Used to understand the direction of the relationship. | Used to understand both the strength and direction of the relationship. |\n",
        "\n",
        "### How These Measures Are Used in Statistical Analysis:\n",
        "- **Covariance**:\n",
        "  - **Understanding the Relationship**: Covariance gives insight into whether two variables increase or decrease together, but without giving a standardized measure of strength. It’s mainly used in the context of portfolio theory (finance) or regression analysis.\n",
        "  - **Limitations**: Since the magnitude of covariance depends on the units of the variables, it’s hard to compare covariance values from different datasets or variables.\n",
        "\n",
        "- **Correlation**:\n",
        "  - **Measuring Strength and Direction**: Correlation is widely used in statistics because it provides both the **strength** (how closely the variables move together) and the **direction** (positive or negative) of the relationship, while being standardized and easier to interpret.\n",
        "  - **Applications**: Common in **data analysis, regression analysis, finance (e.g., stock price movements), and market research**, among others. It helps in decision-making processes, such as determining how strongly two variables are related, and is especially useful in predictive modeling.\n",
        "\n",
        "### Example:\n",
        "- Suppose you have a dataset of hours studied and exam scores.\n",
        "  - If **covariance** is positive, it indicates that as the number of hours studied increases, exam scores also tend to increase.\n",
        "  - If the **correlation** is 0.85, this suggests that there is a strong positive linear relationship between hours studied and exam scores, and the relationship is standardized, making it easy to compare to other datasets.\n",
        "\n",
        "### In Summary:\n",
        "- **Covariance** gives you the direction of the relationship between two variables, but its magnitude depends on the scale of the variables, making it harder to compare across datasets.\n",
        "- **Correlation** standardizes the relationship, making it easier to interpret the strength and direction of the relationship and compare across different datasets."
      ],
      "metadata": {
        "id": "fVCMxJBqSNJs"
      },
      "id": "fVCMxJBqSNJs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. What is the formula for calculating the sample mean? Provide an example calculation for a\n",
        "dataset."
      ],
      "metadata": {
        "id": "w0uMBhlVSQ6y"
      },
      "id": "w0uMBhlVSQ6y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formula for Calculating the Sample Mean:\n",
        "\n",
        "The **sample mean** is the average of a set of data points. It is calculated by summing all the data points and then dividing by the number of data points in the sample.\n",
        "\n",
        "The formula for the **sample mean** (\\(\\bar{x}\\)) is:\n",
        "\n",
        "\\[\n",
        "\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\(\\bar{x}\\) = sample mean\n",
        "- \\(n\\) = number of data points in the sample\n",
        "- \\(x_i\\) = each individual data point\n",
        "- \\(\\sum_{i=1}^{n} x_i\\) = sum of all the data points\n",
        "\n",
        "### Example Calculation:\n",
        "\n",
        "Let’s say we have the following dataset representing the scores of 5 students on a test:\n",
        "\n",
        "\\[\n",
        "\\text{Dataset: } 80, 85, 90, 95, 100\n",
        "\\]\n",
        "\n",
        "#### Step-by-step calculation:\n",
        "\n",
        "1. **Sum of all data points**:\n",
        "\n",
        "\\[\n",
        "80 + 85 + 90 + 95 + 100 = 450\n",
        "\\]\n",
        "\n",
        "2. **Number of data points (n)**:\n",
        "\n",
        "\\[\n",
        "n = 5\n",
        "\\]\n",
        "\n",
        "3. **Sample mean**:\n",
        "\n",
        "\\[\n",
        "\\bar{x} = \\frac{450}{5} = 90\n",
        "\\]\n",
        "\n",
        "So, the **sample mean** of the dataset is **90**.\n",
        "\n",
        "### Summary:\n",
        "- The **sample mean** is simply the average value of the dataset, and it provides a measure of central tendency for the data.\n",
        "- In this example, the average score of the students is **90**."
      ],
      "metadata": {
        "id": "C9CqVtpOScEK"
      },
      "id": "C9CqVtpOScEK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. For a normal distribution data what is the relationship between its measure of central tendency?"
      ],
      "metadata": {
        "id": "NIAWprfaSdUr"
      },
      "id": "NIAWprfaSdUr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a **normal distribution**, the measures of central tendency—**mean**, **median**, and **mode**—are all **equal** and lie at the **center** of the distribution.\n",
        "\n",
        "### Relationship Between the Measures of Central Tendency in a Normal Distribution:\n",
        "- **Mean = Median = Mode**\n",
        "\n",
        "### Explanation:\n",
        "In a normal distribution, the data is symmetrically distributed around the center. This means:\n",
        "1. **Mean**: The average of all the data points. Since the distribution is symmetric, the mean is at the exact center of the distribution.\n",
        "2. **Median**: The middle value when the data is ordered. Because of symmetry, the median is also at the center, where half of the data points fall below it and half fall above it.\n",
        "3. **Mode**: The value that appears most frequently. In a normal distribution, the highest point (the peak) of the curve occurs at the center, so the mode is also at this center.\n",
        "\n",
        "### Visual Representation:\n",
        "- In a **normal distribution curve** (also known as a bell curve), the peak of the curve represents the mean, median, and mode, all of which coincide at the same point.\n",
        "\n",
        "### Why Does This Happen?\n",
        "- The **symmetry** of a normal distribution ensures that the data is evenly spread on both sides of the central point.\n",
        "- As a result, the **mean** (which balances the dataset), the **median** (which splits the dataset in half), and the **mode** (the most frequent value) all align at the same location.\n",
        "\n",
        "### Summary:\n",
        "For a **normal distribution**, the mean, median, and mode are all **equal** and located at the **center** of the distribution. This property is a defining characteristic of normal distributions."
      ],
      "metadata": {
        "id": "oGeNFISrSjoc"
      },
      "id": "oGeNFISrSjoc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. How is covariance different from correlation?"
      ],
      "metadata": {
        "id": "zxkIyyHzSt_b"
      },
      "id": "zxkIyyHzSt_b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Covariance and correlation both measure the relationship between two variables, but they differ in a few key ways:\n",
        "\n",
        "1. **Scale of Measurement:**\n",
        "   - **Covariance** measures the direction of the linear relationship between two variables. It can take any value from negative to positive infinity, depending on how the variables move together. However, its value is affected by the scale of the variables (i.e., the units of measurement), which can make it hard to interpret across different datasets.\n",
        "   - **Correlation**, on the other hand, standardizes the covariance by dividing it by the product of the standard deviations of the two variables. This results in a value between -1 and 1. A correlation of 1 means a perfect positive linear relationship, -1 means a perfect negative linear relationship, and 0 means no linear relationship.\n",
        "\n",
        "2. **Interpretability:**\n",
        "   - **Covariance** values are not easy to interpret because they are not standardized, and the magnitude depends on the units of the variables.\n",
        "   - **Correlation** values are easier to interpret because they are scaled to a fixed range of -1 to 1, making it straightforward to assess the strength and direction of the relationship.\n",
        "\n",
        "3. **Units:**\n",
        "   - **Covariance** has units that are the product of the units of the two variables being compared. For example, if one variable is measured in meters and another in seconds, the covariance will be in meter-seconds.\n",
        "   - **Correlation** is dimensionless because it is a standardized value.\n",
        "\n",
        "In short, while both covariance and correlation describe relationships between variables, **correlation is a normalized and more interpretable version of covariance** that is independent of the scale of the variables."
      ],
      "metadata": {
        "id": "Sq6gSGwBSyXe"
      },
      "id": "Sq6gSGwBSyXe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. How do outliers affect measures of central tendency and dispersion? Provide an example."
      ],
      "metadata": {
        "id": "uj0HVOkPTIF_"
      },
      "id": "uj0HVOkPTIF_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers can have a significant impact on both **measures of central tendency** (mean, median, mode) and **measures of dispersion** (range, variance, standard deviation). Here's how they affect these measures:\n",
        "\n",
        "### 1. **Impact on Measures of Central Tendency:**\n",
        "   - **Mean:** Outliers can **skew the mean** because the mean is sensitive to extreme values. If an outlier is very large or very small, it can pull the mean in that direction, making it unrepresentative of the majority of the data.\n",
        "     - *Example:* Consider the dataset: **[2, 3, 3, 4, 5, 100]**. The mean is calculated as:\n",
        "       \\[\n",
        "       \\text{Mean} = \\frac{(2 + 3 + 3 + 4 + 5 + 100)}{6} = \\frac{117}{6} = 19.5\n",
        "       \\]\n",
        "       This is much higher than the values in the dataset, due to the outlier (100).\n",
        "\n",
        "   - **Median:** The median, being the middle value when the data is ordered, is **less affected by outliers**. Even if an extreme value is present, the median tends to remain stable because it depends only on the middle values.\n",
        "     - *Example:* In the same dataset **[2, 3, 3, 4, 5, 100]**, the median would be the average of the two middle numbers (3 and 4):\n",
        "       \\[\n",
        "       \\text{Median} = \\frac{3 + 4}{2} = 3.5\n",
        "       \\]\n",
        "       This is a better representation of the central tendency compared to the mean.\n",
        "\n",
        "   - **Mode:** The mode, which is the most frequent value in the dataset, is **typically not affected by outliers**, unless the outlier itself occurs frequently.\n",
        "\n",
        "### 2. **Impact on Measures of Dispersion:**\n",
        "   - **Range:** The range is highly sensitive to outliers because it is simply the difference between the largest and smallest values in the dataset. If an outlier is present, it can significantly increase the range.\n",
        "     - *Example:* In the dataset **[2, 3, 3, 4, 5, 100]**, the range is:\n",
        "       \\[\n",
        "       \\text{Range} = 100 - 2 = 98\n",
        "       \\]\n",
        "       The range is inflated due to the outlier.\n",
        "\n",
        "   - **Variance and Standard Deviation:** Both variance and standard deviation are calculated based on squared differences from the mean. Since the mean is affected by outliers, the squared differences will be large for outliers, increasing both variance and standard deviation.\n",
        "     - *Example:* In the same dataset, the outlier (100) will cause the squared difference between the data points and the mean to be much larger than it would be without the outlier. This will increase the overall variance and standard deviation.\n",
        "\n",
        "### Conclusion:\n",
        "- **Mean and range** are most affected by outliers, often leading to a distorted view of the data.\n",
        "- **Median, mode, and interquartile range** (IQR) are more robust to outliers and provide a better summary of the data when outliers are present.\n",
        "\n",
        "In practice, it's important to consider the presence of outliers and decide whether to adjust for them or use more robust measures when analyzing data."
      ],
      "metadata": {
        "id": "_sSotbtwUOBK"
      },
      "id": "_sSotbtwUOBK"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}